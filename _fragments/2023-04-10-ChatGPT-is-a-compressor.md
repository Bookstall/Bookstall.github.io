---
layout: fragment
title: ChatGPT 的本质是无损压缩器
tags: [ChatGPT]
excerpt: ChatGPT 的本质是无损压缩器
keywords: ChatGPT
mathjax: true
---

转载一篇挺有收获的文章 [《【重磅】OpenAI最新解密，ChatGPT的本质是无损压缩器》](https://mp.weixin.qq.com/s/1rBi3P9qiOK8lZcDGUy0jw)，侵删！


## 0、前言

自从 2022 年 12 月 ChatGPT 问世以来，AI 的发展正式进入快车道，整个行业开始 "按日迭代"。**从 1957 年以来，人类在经历了数轮 AI 浪潮后，这次通用人工智能（AGI）是真的要来了**。

我们团队在 2 月发表了对 ChatGPT 技术原理的深度剖析，得到了业内专家朋友们的广泛认可。但随着研究的深入，越来越多的问题浮出水面：

- ChatGPT 强大的一个重要原因是大语言模型的涌现能力（Emergent Abilities），那么涌现能力究竟为何产生呢？

- GPT-5 会有哪些意想不到的性能表现？

- AGI 会走向何方，对社会经济活动又会产生怎样的影响？

在这篇文章中，我们针对以上问题进行深入探讨，并且给出尽可能详实的分析过程。本文浓缩了我们团队的研究成果，共分为以下四个部分：

- 大语言模型的本质：性能强大的无损压缩器

- 视觉信息是知识的富矿：从文本走向多模态

- 大数据时代的数据荒：运用合成数据破局

- AGI 对人类社会经济活动影响：展望与思考

## 1、大语言模型的本质：性能强大的无损压缩器

在最近 OpenAI 的学术分享会中，Jack Rae 提出了一个重要的论断：**大语言模型的本质，其实是一个性能强大的数据无损压缩器**。

$$
\text{LLM} = \text{Compression}
$$

这个论断并不是很直观，但却揭开了 **通用人工智能（Artificial General Intelligence，AGI）** 非常重要的一角，值得高度重视。为了让大家理解这个观点，我们从 **"学习"** 这件事本身来探讨。

上个世纪以来，人类普遍认为 "学习" 是一种人类特有的才能，机器无法真正地掌握 "学习能力"。随着深度神经网络技术的发展，人们通过 **构建 "人工神经元" 来模拟大脑中的 "生物神经元"**，从而使得机器开始具备一定的学习能力。

![生物神经元（左）与人工神经元（右）对比](https://mmbiz.qpic.cn/mmbiz_png/cwUeavcLvr24Gj79NjGS9edtPibtBa8MqLM5Ktia2z8Q20ox28xfaCMeIebWIBBA1T9obUXY7HU8e5iaSQ4FEGHlQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)


而现在，OpenAI 得出了关于 "学习" 的最新结论："学习" 这件事本身，可以理解为对有效信息进行无损压缩的过程。

为了更好地理解这个观点，让我们来做一个思想实验。假设我们需要搭建一个模型，用来处理 **英译中的翻译任务**。

最简单粗暴的方式，就是列举出每个英文单词对应的中文，即 **rule-based mapping**。假设我们 **枚举** 完了所有英文单词的中文对照表，写出了一本 1000 页的词典。

但通过这本词典，我们真的能够有效完成所有英译中的翻译任务吗？答案是否定的。因为 **基于规则的映射系统是非常脆弱的**，只要在翻译过程中遇到一个之前没有遇到过的新单词，系统就崩溃了。

因此，这个模型的翻译性能是很弱的，可以理解为 "该模型没有真正学会翻译"。

---

重点来了，现在请你把这本 1000 页的词典，"无损压缩" 成一本 200 页的手册。**字数减少了，但是信息量不能少**，因此你不能简单地从 1000 页中抽取 200 页构成一本 "小词典"，而需要通过对数据进行 **高维编码**，从而实现 **无损压缩**。

经过压缩后的这本 200 页的手册中，<u>不再是简单的单词映射，而是包含了主谓宾、定状补、虚拟语气、时态、单复数在内的英语语法</u>。相比于一本 "词典" 来说，它更像是一本 "教材"。如下图所示：

![降低任务描述长度等价于增加对任务的理解](https://mmbiz.qpic.cn/mmbiz_png/cwUeavcLvr24Gj79NjGS9edtPibtBa8MqksVsJiaNficwfOIDh1w4cMIZjkKRdpItLPn1v0xBZwET6rfKOicAdJb2w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

注意，在这个压缩的过程中，"学习" 作为一种 **隐式** 的过程，起到了 **知识编码** 的作用。通过把一本 1000 页的词典压缩成一本 200 页的手册，模型 "学会" 了英语语法，掌握了英译中的知识。通过这个例子，不难发现：**学习的本质，可以理解为对有效信息进行无损压缩的过程。压缩率越大，学习的效果就越好**。

根据 OpenAI 的最新观点，基于 GPT 的大语言模型的是 **性能卓越的数据压缩器**。语言模型的本质，是不断预测下一个词的概率分布，从而完成生成式任务。

但是从 "无损压缩" 的角度来看，如果模型对下一个词的预测更加准确，就意味着其对知识的理解更深，从而获得对这个世界更高的分辨率。**随着模型规模的提升，基于信息熵计算出的压缩率也会逐渐提升，这就解释了为什么模型的性能会随着规模的增加而增加**。

而提升模型的压缩率并不只有 "增加规模" 这一种方法，正如 Jack Rae 所言：**Scaling is not all you need**。**更好的算法架构、基于 Plugin 的工具集成、合成数据的运用** 都能够有效提升模型的压缩率，从而实现模型性能的进一步提升。

![提升模型压缩率的几种方法](https://mmbiz.qpic.cn/mmbiz_png/cwUeavcLvr24Gj79NjGS9edtPibtBa8MqqtBEwVibjd7M7030jxPdkQfaEWIpNMobnnhNjMzF8bv4KY96nyguS8A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

最近的 [Toolformer]({% post_url 2023-04-02-Toolformer %}) 就是用来教会 LLM 使用计算器、时间概念、搜索引擎等工具的一个例子。

## 2、视觉信息是知识的富矿：从文本走向多模态

既然大语言模型发展的目标，是不断提升对有效信息的压缩率。那么自然地，**如何获取尽可能多的有效信息**，就成为了一个重要命题。

人类是一种 <u>拥有语言能力的视觉动物</u>，我们大脑皮层中约有三分之一的区域是用于视觉信息解析的（如下图所示）。因此，**视觉信息是人类知识的富矿**。

![大脑皮层中的视觉信号中枢](https://mmbiz.qpic.cn/mmbiz_png/cwUeavcLvr24Gj79NjGS9edtPibtBa8MqOfHuWMaGDNqV0U5PHJeF2lQ1FmqZIlkQZdKkgqzIsnTFqEqlRLWiccw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

举个例子，我们都知道 "太阳从东边升起，西边落下"，这是一个常识。但如果分析一下我们是如何学到这个知识的，我相信 <u>绝大多数人是通过眼睛亲眼看到的，而不仅仅是通过书本学习到的</u>。

推而广之，视觉信息往往是人类知识的源头。由于人类具备语言和写作能力，人们会把 **通过视觉获取到的信息慢慢地转变为文本形态传播出来**。

因此，如果把人类已获得的全部知识看作一座冰山，那么以 "文本" 为载体的数据只是冰山一角，而以 "图像"、"视频" 为载体的数据才是人类知识真正的富矿。这也是 **OpenAI 的 GPT-5 会基于海量互联网视频进行学习** 的原因。

具体而言，

- 如果给模型 **看大量的天文观测视频**，模型有可能学习出一个 **隐式的开普勒定律**；

- 给模型看大量的带电粒子运动轨迹，模型可能会学习出洛伦兹力的数学表达；

- 如果给模型学习强子对撞机的海量实验数据，模型是否可以解开希格斯玻色子的秘密，从而解答物质的 "质量" 之谜；

![基本粒子模型与上帝粒子](https://mmbiz.qpic.cn/mmbiz_png/cwUeavcLvr24Gj79NjGS9edtPibtBa8MqChLteepibSmAT34OLVdJjMiaCEsM1zcdEbpvqZHaicLoWhBg3quiaYJWyQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)



## 3、大数据时代的数据荒：运用合成数据破局

虽然人类社会早已进入了大数据时代，全球经济活动产生了大量数据资产，但是 LLM 所需的训练集膨胀速度更快。根据预测，<u>到 2026 年文本数据将被训练完，图像数据将在 2040 年左右用完</u>。如下图所示：

![大语言模型对互联网存量数据消耗的预测](/images/posts/chatgpt-is-compressor-data-exhausted.png)

> 图片来源：
> 
> - 论文[《Will we run out of data? An analysis of the limits of scaling datasets in Machine Learning》](https://arxiv.org/abs/2211.04325)
> 

这对于 "大力出奇迹" 的大语言模型来说，并不是个好消息。如果训练集体量不够，模型便无法继续 scaling up，从而不断提升性能天花板。

这个时候，**"合成数据"（Synthetic Data）**成为了重要的破局方法。顾名思义，"合成数据" 指的是通过算法生成的训练集，而非从现实世界中采集到的样本。

![Gartner 对合成数据发展的预测](https://p1.itc.cn/q_70/images03/20230409/7993fb270dce4c69945b9180a8f2e787.png)

根据 Gartner 的预测，2026 年模型训练数据中的 50% 将由合成数据构成；2030 年合成数据的质量将全面超过人类标注的真实数据。

OpenAI 在 GPT-4 的 [技术文档](https://arxiv.org/abs/2303.08774) 中重点提到了合成数据的应用，可见 OpenAI 对该领域的重视，如下图所示：

![GPT-4 技术报告中对合成数据应用的探讨](https://mmbiz.qpic.cn/mmbiz_png/cwUeavcLvr24Gj79NjGS9edtPibtBa8Mq2ibbzJqGwzBsibibrWNgNuTUZ5XpdzgE3lDbc4ZBJswzNZ8ocvMNxXGfQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

---

更进一步来看，如果合成数据的质量能够全面超越人类标注的质量，那么未来 AGI 便可以 **自我迭代**，进化的速度会大幅提升。到这时，人类可能就成为 AGI 的 **启动脚本（Boot Loader）**了。

这不禁让我联想到马斯克曾在 2014 年做出的预言。他认为从 "物种进化的尺度" 来看，以人类为代表的 "碳基生命" 可能只是以 "AI" 为代表的 "硅基生命" 的启动脚本。这个预言令人毛骨悚然。放在 2014 年那会儿，绝大部分人会认为这是危言耸听。但是当下我们再回头审视这个判断，不难发现这与 "合成数据" 的发展目标不谋而合。

![Musk 在 2014 年对 AI 发展的判断](https://mmbiz.qpic.cn/mmbiz_png/cwUeavcLvr24Gj79NjGS9edtPibtBa8Mqx9qUIRxxz7V9lyIoial0GR8mJqKhuZDYMxWGIo9qyicoKspQflFEec0Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

最近的 [Segment Anything Model（SAM）]({% post_url 2023-04-11-SAM %}) 中就构建了一个 **数据引擎（Data Engine）**，用来生成分割所需要的图片 Mask。

**合成数据领域的突破，可能成为 AGI 跨过奇点（singularity）的重要里程碑**，让我们拭目以待。

## 4、AGI 对人类社会经济活动影响：展望与思考

在刚结束的 GTC 大会上，NVIDIA 的 CEO 黄仁勋将 ChatGPT 的诞生类比为移动互联网的 iPhone 时刻。但从人类科技发展史的尺度来看，我认为 ChatGPT 的诞生更像是拉开了 **"第四次工业革命"** 的序幕，会带来社会生产力和生产关系的质变。

虽然有点不恰当，但如果把人类看作一台 "生物化学计算机"，我们不妨比较一下人类与 AGI 的效率异同：

- 从 "通信效率" 的角度来看，人类之间的 **数据传输** 主要依靠 **交流**，而交流的本质是以空气为媒介的 **机械波**。与此相对，AGI 之间的数据传输则主要通过 **GPU 之间的 NVLink**，数据传输的带宽显著提升。

- 从 "工作效率" 的角度来看，人类 <u>受限于生物体内复杂的免疫机制、神经元修复机制等原理，需要保持充足的睡眠</u>，才可以换取白天良好的工作状态。但是 AGI 只需要有充足的能源供给，便可以做到 7*24 的高强度作业，**工作效率显著提升**。

- 从 "协作效率" 的角度来看，由 100 个人组成的团队整体的工作效率往往会低于 10 人小组产出总量的 10 倍。随着组织人员规模的增加，人均产出不可避免的下降，需要通过 "富有经验的管理艺术" 才能激发团队协作的活力。相反，对于 AGI 来说，**增加运算节点便可以扩大产能，并不会出现边际效用递减的管理与协作难题**。

![人工智能与人类智能的发展曲线](https://mmbiz.qpic.cn/mmbiz_png/cwUeavcLvr24Gj79NjGS9edtPibtBa8Mq0hmgKlforibFlGRWSTzSzPHY9743vZSg7iah9SeQbLicjuODxibb5iaib18A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

以上分析了相比于人类而言，AGI 的生产力优势。但是 **人类** 在以下几个重点方面依然具备着 **不可替代的价值**：

- 首先，虽然AGI在知识的广度上会远超人类，但是 **在具体领域的知识深度上**，人类目前依然占据优势。

  - 以金融投资为例，一位资深的投资经理可以根据不完整的市场信息做出模糊推断，从而获得超额收益；以科学研究为例，一位优秀的科学家可以从看似无关紧要的实验误差中推断出全新的理论体系。这些都是当前 AGI 难以企及的。

- 其次，社会经济活动的运转，**高度依赖于人与人之间的 "信任"**，这种信任是 AGI 难以取代的。

  - 比如当你去医院看病的时候，即使 AGI 能够根据你的症状描述做出相当准确的诊断，你依然大概率会拿着诊断结果去咨询边上的人类医生，寻求一个值得信任的诊疗建议。类似的“信任机制”构成了医疗、教育、金融等领域中经济活动的重要基石。

随着 AGI 的发展，许多经济活动的游戏规则会悄然发生改变，而 **这个规则改变的契机，则会以 AGI 在该领域超过人类中的最强者作为分界线**，正如 AlphaGo 的诞生彻底改变了围棋界的规则一样。




## 5、总结

**这是最好的时代，也是最坏的时代。悲观者可能永远正确，但确实毫无意义。**

纵观历史，人类科技史的发展并不是连续的，而是跳跃的。或许我们正在经历的正是一次人类科技水平的跳跃，无论如何，能够亲眼见证并参与其中，我们都是幸运的。

最后，分享一句我特别喜欢的话，这是 OpenAI 的 CEO Sam Altman 在 30 岁生日时给自己的人生建议：

> **The days are long but the decades are short.**



## 参考

- [《【重磅】OpenAI最新解密，ChatGPT的本质是无损压缩器》](https://mp.weixin.qq.com/s/1rBi3P9qiOK8lZcDGUy0jw)

无损压缩器（Non-destructive Compressor）





