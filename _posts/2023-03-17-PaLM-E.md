---
layout: post
author: bookstall
tags: AI, 论文
categories: [AI, 论文]
excerpt: 使用多模态具身模型 PaLM-E 来控制机器人：将连续的传感器数据直接整合到语言模型里，从而使得语言模型能够做出更有根据的推理。由于使用了 2022 年谷歌发布的 PaLM 作为预训练语言模型，因此命名 PaLM-E（PaLM Embodied）
keywords: AI, 论文
title: PaLM-E：多模态具身模型
mathjax: true
---

## 前言



## PaLM-E：An Embodied Multimodal Language Model

> - [论文地址](https://palm-e.github.io/assets/palm-e.pdf)
>
> - [arxiv](https://arxiv.org/abs/2303.03378)
>
> - [论文主页](https://palm-e.github.io/)

![PaLM-E paper](https://image.jiqizhixin.com/uploads/editor/4802ca6a-cd75-41c1-90b0-b0629241eca1/640.png)


### 方法

PaLM-E 的架构思想是将 **连续的具身观察结果（例如图像、状态估计或其他传感器模态）** 注入到预训练语言模型的语言嵌入空间中。具体来说，PaLM-E 将连续信息以 **类似于语言 token 的方式注入到语言模型** 中。

它不是那种常见的编码器-解码器架构模型，而是一种 **只具有解码器** 的 LLM。

具体到输入上，PaLM-E 的输入包括文本和（多个）连续观察。与这些观察相对应的多模态 token 与文本交错形成多模态句子。例如多模态句子 Q（给出一个提问）：`What happened between  <img_1> and  <img_2> ?`，其中 `<img_i>` 表示图像的嵌入。

PaLM-E 的输出是由 **模型自回归** 生成的文本，可以是 <u>问题的答案</u>，也可以是 PaLM-E 以文本形式生成的 <u>应该由机器人执行的一系列决策</u>。 

![PaLM-E 整体框架](https://image.jiqizhixin.com/uploads/editor/f091438a-0a94-4598-811a-4bb0dd65ac5c/640.png)



## 参考

- 机器之心：[5620亿参数，最大多模态模型控制机器人，谷歌把具身智能玩出新高度](https://www.jiqizhixin.com/articles/2023-03-09-2)




